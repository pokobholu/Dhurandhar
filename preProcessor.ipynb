{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef29333-1974-412d-a9de-ade798820ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting newspaper3k\n",
      "  Using cached newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: requests in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (4.13.5)\n",
      "Collecting pdfplumber\n",
      "  Using cached pdfplumber-0.11.9-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (5.3.0)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from newspaper3k) (12.0.0)\n",
      "Requirement already satisfied: PyYAML>=3.11 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from newspaper3k) (6.0.3)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from newspaper3k) (1.2.0)\n",
      "Requirement already satisfied: nltk>=3.2.1 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from newspaper3k) (3.9.2)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
      "  Using cached feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from newspaper3k) (5.1.2)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
      "  Using cached feedfinder2-0.0.4-py3-none-any.whl\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
      "  Using cached jieba3k-0.35.1-py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from newspaper3k) (2.9.0.post0)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
      "  Using cached tinysegmenter-0.3-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Collecting pdfminer.six==20251230 (from pdfplumber)\n",
      "  Using cached pdfminer_six-20251230-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Using cached pypdfium2-5.3.0-py3-none-win_amd64.whl.metadata (67 kB)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from pdfminer.six==20251230->pdfplumber) (46.0.3)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.23)\n",
      "Requirement already satisfied: six in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
      "  Using cached sgmllib3k-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: click in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (2025.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (2.1.0)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (3.20.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from click->nltk>=3.2.1->newspaper3k) (0.4.6)\n",
      "Using cached newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "Using cached pdfplumber-0.11.9-py3-none-any.whl (60 kB)\n",
      "Using cached pdfminer_six-20251230-py3-none-any.whl (6.6 MB)\n",
      "Using cached feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
      "Using cached pypdfium2-5.3.0-py3-none-win_amd64.whl (3.1 MB)\n",
      "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, pypdfium2, feedparser, feedfinder2, pdfminer.six, pdfplumber, newspaper3k\n",
      "\n",
      "   -------- ------------------------------- 2/9 [jieba3k]\n",
      "   -------- ------------------------------- 2/9 [jieba3k]\n",
      "   -------- ------------------------------- 2/9 [jieba3k]\n",
      "   -------- ------------------------------- 2/9 [jieba3k]\n",
      "   -------- ------------------------------- 2/9 [jieba3k]\n",
      "   ------------- -------------------------- 3/9 [pypdfium2]\n",
      "   ------------- -------------------------- 3/9 [pypdfium2]\n",
      "   ------------- -------------------------- 3/9 [pypdfium2]\n",
      "   ----------------- ---------------------- 4/9 [feedparser]\n",
      "   ----------------- ---------------------- 4/9 [feedparser]\n",
      "   -------------------------- ------------- 6/9 [pdfminer.six]\n",
      "   -------------------------- ------------- 6/9 [pdfminer.six]\n",
      "   -------------------------- ------------- 6/9 [pdfminer.six]\n",
      "   -------------------------- ------------- 6/9 [pdfminer.six]\n",
      "   -------------------------- ------------- 6/9 [pdfminer.six]\n",
      "   ------------------------------- -------- 7/9 [pdfplumber]\n",
      "   ----------------------------------- ---- 8/9 [newspaper3k]\n",
      "   ----------------------------------- ---- 8/9 [newspaper3k]\n",
      "   ---------------------------------------- 9/9 [newspaper3k]\n",
      "\n",
      "Successfully installed feedfinder2-0.0.4 feedparser-6.0.12 jieba3k-0.35.1 newspaper3k-0.2.8 pdfminer.six-20251230 pdfplumber-0.11.9 pypdfium2-5.3.0 sgmllib3k-1.0.0 tinysegmenter-0.3\n",
      "Collecting lxml_html_clean\n",
      "  Using cached lxml_html_clean-0.4.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\nikita\\anaconda_main\\lib\\site-packages (from lxml_html_clean) (5.3.0)\n",
      "Using cached lxml_html_clean-0.4.3-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: lxml_html_clean\n",
      "Successfully installed lxml_html_clean-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install newspaper3k pandas requests beautifulsoup4 pdfplumber lxml\n",
    "!pip install lxml_html_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfe63e52-0f11-4790-a827-4713dd6504c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import datetime\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from io import BytesIO\n",
    "import pdfplumber\n",
    "\n",
    "def preprocess_articles_to_csv(listing_url, csv_filename=\"articles.csv\", same_domain_only=True, min_text_length=200):\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = requests.get(listing_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    base_domain = urlparse(listing_url).netloc\n",
    "    urls = set()\n",
    "\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        href = a[\"href\"]\n",
    "        full_url = urljoin(listing_url, href)\n",
    "        parsed = urlparse(full_url)\n",
    "\n",
    "        if not parsed.scheme.startswith(\"http\"):\n",
    "            continue\n",
    "        if same_domain_only and parsed.netloc != base_domain:\n",
    "            continue\n",
    "        if re.search(r\"(login|signup|about|contact|privacy|terms)\", full_url, re.I):\n",
    "            continue\n",
    "        urls.add(full_url)\n",
    "\n",
    "    urls = list(urls)\n",
    "    if not urls:\n",
    "        return None\n",
    "\n",
    "    records = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            text = \"\"\n",
    "            timestamp = None\n",
    "\n",
    "            if url.lower().endswith(\".pdf\"):\n",
    "                r = requests.get(url, timeout=10)\n",
    "                r.raise_for_status()\n",
    "                with pdfplumber.open(BytesIO(r.content)) as pdf:\n",
    "                    for page in pdf.pages:\n",
    "                        page_text = page.extract_text()\n",
    "                        if page_text:\n",
    "                            text += page_text + \"\\n\"\n",
    "                timestamp = datetime.datetime.now()\n",
    "            else:\n",
    "                article = Article(url)\n",
    "                article.download()\n",
    "                article.parse()\n",
    "                text = article.text\n",
    "                timestamp = article.publish_date\n",
    "\n",
    "            text = text.strip()\n",
    "            if not text or len(text) < min_text_length:\n",
    "                continue\n",
    "\n",
    "            records.append({\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"text\": text,\n",
    "                \"timestamp\": timestamp or datetime.datetime.now(),\n",
    "                \"source_type\": \"Government\" if \".gov\" in url else \"News\",\n",
    "                \"domain\": urlparse(url).netloc,\n",
    "                \"label_truth\": None\n",
    "            })\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if records:\n",
    "        df = pd.DataFrame(records)\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        return csv_filename\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d132d93-66f4-4369-87c6-1732a4bc3ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda_main]",
   "language": "python",
   "name": "conda-env-anaconda_main-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
